{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_TicTacToe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjSw0BvTsEjmnYvNJdO/WF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inforeqd512/QLearning/blob/main/RL_TicTacToe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09zQDJ8boz15"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs_GTXqantDk"
      },
      "source": [
        "# Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaQuOM1Mnu90"
      },
      "source": [
        "On the Board\n",
        "\n",
        "Player playing $X$ will be denoted by 1\n",
        "\n",
        "Player playing $O$ will be denoted by -1\n",
        "\n",
        "Board in the environment. State is the position of the board after a move from any player. Board also provides the possible set of actions\n",
        "\n",
        "Action to be performed is chosen by the agent on the current state of the board"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO0tWLLZnHm1"
      },
      "source": [
        "# Board"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtDnMMJ_nHP2"
      },
      "source": [
        "class Board:\n",
        "  \"\"\" Class that represents the game board of Tic Tac Toe \"\"\"\n",
        "\n",
        "  playerX = 1\n",
        "  playerO = -1\n",
        "\n",
        "  def __init__(self, rows=3, cols=3):\n",
        "    self.rows = rows\n",
        "    self.cols = cols \n",
        "    self.resetGame()\n",
        "\n",
        "  def resetGame(self):\n",
        "    self.state = np.zeros((self.rows, self.cols), dtype=np.int8)\n",
        "\n",
        "  def checkWinner(self):\n",
        "    \"\"\"  return winner symbol, if one exists. 0 if no winner\"\"\"\n",
        "\n",
        "    symbols = np.unique(self.state) #unique values , 0, 1, -1\n",
        "    symbols = symbols[np.nonzero(symbols)] #remove 0's\n",
        "    winning_symbol = 0 #no winner yet\n",
        "\n",
        "    for symbol in symbols:\n",
        "      #check rows\n",
        "      row = np.any(np.all(self.state == symbol, axis=1))\n",
        "\n",
        "      #check cols\n",
        "      col = np.any(np.all(self.state == symbol, axis=0))\n",
        "\n",
        "      #check diagonals\n",
        "      diag1 = np.array([self.state[0,0], self.state[1,1], self.state[2,2]])\n",
        "      diag1 = np.all(diag1 == symbol)\n",
        "\n",
        "      diag2 = np.array([self.state[2,0], self.state[1,1], self.state[0,2]])\n",
        "      diag2 = np.all(diag2 == symbol)\n",
        "\n",
        "      # Check if state has winner and return winner in that case\n",
        "      if row or col or diag1 or diag2:\n",
        "        winning_symbol = symbol\n",
        "        break\n",
        "  \n",
        "    return winning_symbol\n",
        "\n",
        "  def getAvailablePos(self):\n",
        "    \"\"\"  Get state positions that have no value ie zeros \"\"\"\n",
        "    return np.argwhere(self.state == 0)\n",
        "\n",
        "  def checkGameEnded(self):\n",
        "    \"\"\" Check if game has ended by observing if there any possible moves left \"\"\"\n",
        "    return len(self.getAvailablePos()) == 0 \n",
        "\n",
        "  def setPosition(self, x, y, symbol):\n",
        "    \"\"\"  Set state at position (x,y) with symbol \"\"\"\n",
        "    self.state[x,y] = symbol\n",
        "\n",
        "  def getStateHash(self):\n",
        "    \"\"\"  Get hash key of state \"\"\"\n",
        "    return np.array2string(self.state)\n",
        "\n",
        "  def getActionsHash(self):\n",
        "    \"\"\"  Get list of hash for all positions where no symbols are yet put \"\"\"\n",
        "    actions = self.getAvailablePos()\n",
        "    hash_list = []\n",
        "    for action in actions:\n",
        "      hash_list.append(self.getActionHash(action))\n",
        "    return hash_list\n",
        "  \n",
        "  def getActionHash(self, action):\n",
        "    \"\"\"  Get hash key of single action \"\"\"\n",
        "    return np.array2string(action)\n",
        "\n",
        "  def performAction(self, action_to_perform, symbol):\n",
        "    \"\"\"  Perform the action on current board \"\"\"\n",
        "    self.setPosition(action_to_perform[0], action_to_perform[1], symbol)\n",
        "    return self\n",
        "      "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSWPabSDToIi"
      },
      "source": [
        "class Agent:\n",
        "  \"\"\" Class that represents the player \n",
        "      symbol is 1 for 'X' or -1 for 'O' \n",
        "      policy_trainer is initialised with epsilon greedy set to exploration_probability which is reduced overtime\"\"\"\n",
        "\n",
        "  def __init__(self, symbol, exploration_probability):\n",
        "    self.symbol = symbol\n",
        "    self.policy_trainer = PolicyTrainer(exploration_probability=exploration_probability)\n",
        "    return\n",
        "\n",
        "  def performActionPerPolicy(self, state_hash, actions_hash, possible_actions, current_state):\n",
        "    \"\"\" per the explore and exploitation with current epsilon \"\"\"\n",
        "    action = self.policy_trainer.chooseAction(state_hash, actions_hash, possible_actions)\n",
        "    self.policy_trainer.performAction(current_state, action, self.symbol)\n",
        "\n",
        "  def epsilonDecayPerIterations(self, num_iterations):\n",
        "    \"\"\" gradually reduces probabilities per iteration but not completely eliminate it\"\"\"\n",
        "    # Reduce probability to explore during training\n",
        "    # Do not remove completely \n",
        "    \n",
        "    # Decaying epsilon-greedy: Does the same as epsilon-greedy, however, the epsilon value starts out near 1,\n",
        "    # and decays over time according to γ to power of x where x represents the iteration the agent is in. \n",
        "    # For γ 0.99 is used per https://theses.ubn.ru.nl/bitstream/handle/123456789/5216/Nieuwdorp,%20T._BSc_Thesis_2017.pdf?sequence=1\n",
        "        \n",
        "    if self.policy_trainer.exploration_probability > 0.2:\n",
        "      decay = 0.99 ** num_iterations\n",
        "      self.policy_trainer.exploration_probability = decay\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLEV9tTvYLQZ"
      },
      "source": [
        "class PolicyTrainer:\n",
        "  \"\"\"\n",
        "      exploration_probability (float) epsilon greedy value\n",
        "      learning_rate (float)\n",
        "      discount_factor (float)\n",
        "      Q (dict)\n",
        "  \"\"\"\n",
        "  def __init__(self, exploration_probability = 1.0, learning_rate = 0.1, discount_factor = 0.9, Q = {}):\n",
        "    self.Q = Q\n",
        "    self.learning_rate = learning_rate\n",
        "    self.discount_factor = discount_factor\n",
        "    self.exploration_probability = exploration_probability\n",
        "    return\n",
        "\n",
        "  def getStateActionPairKey(self, current_state_hash, current_action_hash):\n",
        "    \"\"\" Returns state-pair hash key, requires separate state and action hash keys first \"\"\"\n",
        "    return current_state_hash + current_action_hash\n",
        "\n",
        "  def getValueQ(self, current_state_hash, current_action_hash):\n",
        "    \"\"\" Get the quality value of a given action in a given state,\n",
        "            returns 0 if the state-action pair has not been seen before.\n",
        "            Input is state and action hash key                          \"\"\"\n",
        "    state_action_pair_key = self.getStateActionPairKey(current_state_hash, current_action_hash)\n",
        "    q_value = 0 \n",
        "    if state_action_pair_key in self.Q:\n",
        "      q_value = self.Q[state_action_pair_key]\n",
        "    else:\n",
        "      self.setValueQ(current_state_hash, current_action_hash, q_value)\n",
        "\n",
        "    return q_value\n",
        "\n",
        "  def setValueQ(self, current_state_hash, current_action_hash, value):\n",
        "    \"\"\" Set value in Q \"\"\"\n",
        "    state_action_pair_key = self.getStateActionPairKey(current_state_hash, current_action_hash)\n",
        "    self.Q[state_action_pair_key] = value\n",
        "    return\n",
        "\n",
        "  def rewardFunction(self, next_state, symbol):\n",
        "    \"\"\" when the chosen action is performed on a state, then we get a new state\n",
        "    and associated reward from this transition is computed here\n",
        "    if next state is winner then reward is 1 else 0 \"\"\"\n",
        "    winner = next_state.checkWinner()\n",
        "    reward = 0 \n",
        "    if winner == symbol:\n",
        "      reward = 1\n",
        "    \n",
        "    return reward\n",
        "\n",
        "  def chooseAction(self, state_hash, actions_hash, possible_actions):\n",
        "    \"\"\" choose action per epsilon greedy explore/exploit policy \"\"\"\n",
        "    #Explore\n",
        "    if random.random() < self.exploration_probability:\n",
        "      action = self.chooseRandomAction(possible_actions)\n",
        "    else:\n",
        "      #Exploit\n",
        "      action = self.chooseBestAction(state_hash, actions_hash, possible_actions)\n",
        "    return action\n",
        "\n",
        "  def chooseRandomAction(self, possible_actions):\n",
        "    \"\"\" choose random action from list of possible actions in a state \"\"\"\n",
        "    random_idx = np.random.choice(possible_actions.shape[0])\n",
        "    action_pos = possible_actions[random_idx]\n",
        "    return action_pos\n",
        "\n",
        "  def chooseBestAction(self, current_state_hash, actions_hash, possible_actions):\n",
        "    \"\"\" Get best action given a set of possible actions in a given state \"\"\"\n",
        "    # Pick a random action at first\n",
        "    random_idx = np.random.choice(possible_actions.shape[0])\n",
        "    best_action = possible_actions[random_idx]\n",
        "\n",
        "    # Find action that given largest Q in given state\n",
        "    maxQ = 0 \n",
        "    for action_hash, action in zip(actions_hash, possible_actions):\n",
        "      tmpQ = self.getValueQ(current_state_hash, action_hash)\n",
        "      if maxQ < tmpQ:\n",
        "        maxQ = tmpQ\n",
        "        best_action = action\n",
        "\n",
        "    return best_action\n",
        "\n",
        "  def getMaxQ(self, next_state):\n",
        "    \"\"\" go through all possible actions in a state \n",
        "    and pick the one with the highest quality value \"\"\"\n",
        "    actions_hash = next_state.getActionsHash()\n",
        "    state_hash = next_state.getStateHash()\n",
        "\n",
        "    # Find action that given largest Q in given state\n",
        "    maxQ = 0 \n",
        "    for action_hash in actions_hash:\n",
        "      tmpQ = self.getValueQ(state_hash, action_hash)\n",
        "      if maxQ < tmpQ:\n",
        "        maxQ = tmpQ\n",
        "\n",
        "    return maxQ\n",
        "\n",
        "  def performAction(self, current_state, current_action, symbol):\n",
        "    \"\"\" Implements Q-learning iterative algorithm \"\"\"\n",
        "    current_state_hash = current_state.getStateHash()\n",
        "    current_action_hash = current_state.getActionHash(current_action)\n",
        "\n",
        "    # Get current Q Value\n",
        "    currentQ = self.getValueQ(current_state_hash, current_action_hash)\n",
        "\n",
        "    next_state = current_state.performAction(current_action, symbol)\n",
        "\n",
        "    newQ = (1 - self.learning_rate) * currentQ\n",
        "    newQ += self.learning_rate * (self.rewardFunction(next_state, symbol) + self.discount_factor * self.getMaxQ(next_state) - currentQ)\n",
        "\n",
        "    self.setValueQ(current_state_hash, current_action_hash, newQ)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHcSV1SNQcsM"
      },
      "source": [
        "# Q-Learning : Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZIXiKY_RtYf"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import random"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW2Kf4WpnDLu"
      },
      "source": [
        "def simulate(iterations):\n",
        "  \"\"\" iterations (int) \"\"\"\n",
        "\n",
        "  # Construct game board\n",
        "  game = Board()\n",
        "\n",
        " # Epsilon-greedy \n",
        "  exploration_probability = 1.0\n",
        "\n",
        "  # Initiatlise players\n",
        "  playerX = Agent(Board.playerX, exploration_probability)\n",
        "  playerO = Agent(Board.playerO, exploration_probability)\n",
        "\n",
        "  # Counters for wins of each agent and total number of games\n",
        "  nbr_wins_playerX = 0\n",
        "  nbr_wins_playerO = 0\n",
        "  nbr_games = 0\n",
        "\n",
        "  # Pick current player\n",
        "  current_player = playerX\n",
        "\n",
        "  for i in tqdm(range(iterations)):\n",
        "\n",
        "    print(\"\\nGame :\", i)\n",
        "\n",
        "    # play full games in each iteration\n",
        "    while not game.checkGameEnded():\n",
        "      possible_actions = game.getAvailablePos()\n",
        "      state_hash = game.getStateHash()\n",
        "      actions_hash = game.getActionsHash()\n",
        "      current_player.performActionPerPolicy(state_hash, actions_hash, possible_actions, game)\n",
        "\n",
        "      # Check if there is a winner\n",
        "      winner = game.checkWinner() # Returns 0 if there is no winner\n",
        "      if winner != 0: #winner is when it's 1 or -1\n",
        "          # Add to count for corresponding winner\n",
        "          if winner == playerX.symbol:\n",
        "              nbr_wins_playerX += 1\n",
        "          else:\n",
        "              nbr_wins_playerO += 1\n",
        "          break\n",
        "\n",
        "      # Swap player\n",
        "      if current_player == playerX:\n",
        "          current_player = playerO\n",
        "      else:\n",
        "          current_player = playerX\n",
        "\n",
        "    #when the full game is finished, then increment and print metrics\n",
        "    nbr_games += 1\n",
        "    if winner == 0:\n",
        "      print(\"\\nDraw\")\n",
        "    else:\n",
        "      print(winner, \"wins\")\n",
        "    print(\"board :\\n\", game.state)\n",
        "    print(\"\\nnumber of games :\", nbr_games)\n",
        "    print(\"\\nplayerX epsilon :\", playerX.policy_trainer.exploration_probability)\n",
        "    print(\"\\nplayerO epsilon :\", playerO.policy_trainer.exploration_probability)\n",
        "    game.resetGame()\n",
        "    playerX.epsilonDecayPerIterations(nbr_games)\n",
        "    playerO.epsilonDecayPerIterations(nbr_games)\n",
        "\n",
        "  # Print outcome\n",
        "  print(nbr_wins_playerX, nbr_wins_playerO, nbr_games)    \n",
        "  print(\"Win percentage: Agent X {:.2%}, Agent O {:.2%}.\".format(nbr_wins_playerX/nbr_games, nbr_wins_playerO/nbr_games))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upb8dmgV07x-"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ynzHkISBxX",
        "outputId": "bd6c8d93-4fed-468b-f6af-1decc1404f43"
      },
      "source": [
        "simulate(50)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 6/50 [00:00<00:00, 51.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Game : 0\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  0  1]\n",
            " [-1  1  0]\n",
            " [-1  1  0]]\n",
            "\n",
            "playerX epsilon : 1.0\n",
            "\n",
            "playerO epsilon : 1.0\n",
            "\n",
            "Game : 1\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [-1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.99\n",
            "\n",
            "playerO epsilon : 0.99\n",
            "\n",
            "Game : 2\n",
            "-1 wins\n",
            "board :\n",
            " [[ 1  1  0]\n",
            " [-1 -1 -1]\n",
            " [ 1  0 -1]]\n",
            "\n",
            "playerX epsilon : 0.9801\n",
            "\n",
            "playerO epsilon : 0.9801\n",
            "\n",
            "Game : 3\n",
            "-1 wins\n",
            "board :\n",
            " [[ 1  0  0]\n",
            " [-1 -1 -1]\n",
            " [ 0  1  0]]\n",
            "\n",
            "playerX epsilon : 0.970299\n",
            "\n",
            "playerO epsilon : 0.970299\n",
            "\n",
            "Game : 4\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [-1 -1  1]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.96059601\n",
            "\n",
            "playerO epsilon : 0.96059601\n",
            "\n",
            "Game : 5\n",
            "1 wins\n",
            "board :\n",
            " [[ 0  0  1]\n",
            " [-1 -1  1]\n",
            " [ 0 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.9509900498999999\n",
            "\n",
            "playerO epsilon : 0.9509900498999999\n",
            "\n",
            "Game : 6\n",
            "1 wins\n",
            "board :\n",
            " [[-1  1 -1]\n",
            " [ 0 -1  0]\n",
            " [ 1  1  1]]\n",
            "\n",
            "playerX epsilon : 0.941480149401\n",
            "\n",
            "playerO epsilon : 0.941480149401\n",
            "\n",
            "Game : 7\n",
            "1 wins\n",
            "board :\n",
            " [[ 1  1 -1]\n",
            " [ 1 -1  0]\n",
            " [ 1 -1  0]]\n",
            "\n",
            "playerX epsilon : 0.9320653479069899\n",
            "\n",
            "playerO epsilon : 0.9320653479069899\n",
            "\n",
            "Game : 8\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  0  1]\n",
            " [-1 -1  1]\n",
            " [ 1  1 -1]]\n",
            "\n",
            "playerX epsilon : 0.9227446944279201\n",
            "\n",
            "playerO epsilon : 0.9227446944279201\n",
            "\n",
            "Game : 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 18/50 [00:00<00:00, 51.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 wins\n",
            "board :\n",
            " [[ 0 -1  1]\n",
            " [-1  1  0]\n",
            " [ 1  0 -1]]\n",
            "\n",
            "playerX epsilon : 0.9135172474836408\n",
            "\n",
            "playerO epsilon : 0.9135172474836408\n",
            "\n",
            "Game : 10\n",
            "-1 wins\n",
            "board :\n",
            " [[ 1  1  0]\n",
            " [-1 -1 -1]\n",
            " [ 0  0  1]]\n",
            "\n",
            "playerX epsilon : 0.9043820750088044\n",
            "\n",
            "playerO epsilon : 0.9043820750088044\n",
            "\n",
            "Game : 11\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  0  1]\n",
            " [-1  0  0]\n",
            " [-1  1  0]]\n",
            "\n",
            "playerX epsilon : 0.8953382542587164\n",
            "\n",
            "playerO epsilon : 0.8953382542587164\n",
            "\n",
            "Game : 12\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [ 1 -1 -1]\n",
            " [-1  1 -1]]\n",
            "\n",
            "playerX epsilon : 0.8863848717161292\n",
            "\n",
            "playerO epsilon : 0.8863848717161292\n",
            "\n",
            "Game : 13\n",
            "\n",
            "Draw\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [ 1 -1 -1]\n",
            " [-1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.8775210229989678\n",
            "\n",
            "playerO epsilon : 0.8775210229989678\n",
            "\n",
            "Game : 14\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [ 1 -1  0]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.8687458127689782\n",
            "\n",
            "playerO epsilon : 0.8687458127689782\n",
            "\n",
            "Game : 15\n",
            "\n",
            "Draw\n",
            "board :\n",
            " [[-1 -1  1]\n",
            " [ 1 -1 -1]\n",
            " [-1  1  1]]\n",
            "\n",
            "playerX epsilon : 0.8600583546412884\n",
            "\n",
            "playerO epsilon : 0.8600583546412884\n",
            "\n",
            "Game : 16\n",
            "-1 wins\n",
            "board :\n",
            " [[ 1 -1 -1]\n",
            " [ 1  1 -1]\n",
            " [ 0  1 -1]]\n",
            "\n",
            "playerX epsilon : 0.8514577710948755\n",
            "\n",
            "playerO epsilon : 0.8514577710948755\n",
            "\n",
            "Game : 17\n",
            "-1 wins\n",
            "board :\n",
            " [[ 0  0  1]\n",
            " [ 1  1 -1]\n",
            " [-1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.8429431933839268\n",
            "\n",
            "playerO epsilon : 0.8429431933839268\n",
            "\n",
            "Game : 18\n",
            "-1 wins\n",
            "board :\n",
            " [[ 1  0  0]\n",
            " [ 1 -1  1]\n",
            " [-1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.8345137614500875\n",
            "\n",
            "playerO epsilon : 0.8345137614500875\n",
            "\n",
            "Game : 19\n",
            "\n",
            "Draw\n",
            "board :\n",
            " [[-1  1 -1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.8261686238355866\n",
            "\n",
            "playerO epsilon : 0.8261686238355866\n",
            "\n",
            "Game : 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 30/50 [00:00<00:00, 52.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Draw\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [ 1 -1 -1]\n",
            " [ 1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.8179069375972308\n",
            "\n",
            "playerO epsilon : 0.8179069375972308\n",
            "\n",
            "Game : 21\n",
            "-1 wins\n",
            "board :\n",
            " [[ 1 -1  1]\n",
            " [ 0 -1  0]\n",
            " [ 0 -1  0]]\n",
            "\n",
            "playerX epsilon : 0.8097278682212584\n",
            "\n",
            "playerO epsilon : 0.8097278682212584\n",
            "\n",
            "Game : 22\n",
            "1 wins\n",
            "board :\n",
            " [[ 1  1  1]\n",
            " [ 0 -1  0]\n",
            " [-1  0 -1]]\n",
            "\n",
            "playerX epsilon : 0.8016305895390459\n",
            "\n",
            "playerO epsilon : 0.8016305895390459\n",
            "\n",
            "Game : 23\n",
            "1 wins\n",
            "board :\n",
            " [[ 1  0  0]\n",
            " [ 1 -1 -1]\n",
            " [ 1  0  0]]\n",
            "\n",
            "playerX epsilon : 0.7936142836436554\n",
            "\n",
            "playerO epsilon : 0.7936142836436554\n",
            "\n",
            "Game : 24\n",
            "\n",
            "Draw\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [ 1  1 -1]\n",
            " [-1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.7856781408072188\n",
            "\n",
            "playerO epsilon : 0.7856781408072188\n",
            "\n",
            "Game : 25\n",
            "\n",
            "Draw\n",
            "board :\n",
            " [[ 1 -1 -1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.7778213593991467\n",
            "\n",
            "playerO epsilon : 0.7778213593991467\n",
            "\n",
            "Game : 26\n",
            "1 wins\n",
            "board :\n",
            " [[ 0  0 -1]\n",
            " [ 1  1  1]\n",
            " [-1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.7700431458051551\n",
            "\n",
            "playerO epsilon : 0.7700431458051551\n",
            "\n",
            "Game : 27\n",
            "\n",
            "Draw\n",
            "board :\n",
            " [[ 1 -1  1]\n",
            " [ 1  1 -1]\n",
            " [-1  1 -1]]\n",
            "\n",
            "playerX epsilon : 0.7623427143471035\n",
            "\n",
            "playerO epsilon : 0.7623427143471035\n",
            "\n",
            "Game : 28\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  1 -1]\n",
            " [ 1 -1  1]\n",
            " [-1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.7547192872036326\n",
            "\n",
            "playerO epsilon : 0.7547192872036326\n",
            "\n",
            "Game : 29\n",
            "-1 wins\n",
            "board :\n",
            " [[ 1  1 -1]\n",
            " [ 1  1 -1]\n",
            " [-1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.7471720943315961\n",
            "\n",
            "playerO epsilon : 0.7471720943315961\n",
            "\n",
            "Game : 30\n",
            "1 wins\n",
            "board :\n",
            " [[-1  0  1]\n",
            " [ 1  1 -1]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.7397003733882802\n",
            "\n",
            "playerO epsilon : 0.7397003733882802\n",
            "\n",
            "Game : 31\n",
            "1 wins\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [ 0  1 -1]\n",
            " [ 0  1 -1]]\n",
            "\n",
            "playerX epsilon : 0.7323033696543975\n",
            "\n",
            "playerO epsilon : 0.7323033696543975\n",
            "\n",
            "Game : 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 42/50 [00:00<00:00, 52.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 wins\n",
            "board :\n",
            " [[-1  1  1]\n",
            " [-1  1  1]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.7249803359578534\n",
            "\n",
            "playerO epsilon : 0.7249803359578534\n",
            "\n",
            "Game : 33\n",
            "1 wins\n",
            "board :\n",
            " [[ 1  1  1]\n",
            " [-1  1 -1]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.7177305325982749\n",
            "\n",
            "playerO epsilon : 0.7177305325982749\n",
            "\n",
            "Game : 34\n",
            "1 wins\n",
            "board :\n",
            " [[-1 -1  0]\n",
            " [ 1  1  1]\n",
            " [-1  1  0]]\n",
            "\n",
            "playerX epsilon : 0.7105532272722921\n",
            "\n",
            "playerO epsilon : 0.7105532272722921\n",
            "\n",
            "Game : 35\n",
            "1 wins\n",
            "board :\n",
            " [[-1  1 -1]\n",
            " [ 1  1  1]\n",
            " [-1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.7034476949995692\n",
            "\n",
            "playerO epsilon : 0.7034476949995692\n",
            "\n",
            "Game : 36\n",
            "1 wins\n",
            "board :\n",
            " [[ 0  0  1]\n",
            " [ 0  1 -1]\n",
            " [ 1  0 -1]]\n",
            "\n",
            "playerX epsilon : 0.6964132180495735\n",
            "\n",
            "playerO epsilon : 0.6964132180495735\n",
            "\n",
            "Game : 37\n",
            "1 wins\n",
            "board :\n",
            " [[ 1 -1  1]\n",
            " [-1  1 -1]\n",
            " [-1  1  1]]\n",
            "\n",
            "playerX epsilon : 0.6894490858690777\n",
            "\n",
            "playerO epsilon : 0.6894490858690777\n",
            "\n",
            "Game : 38\n",
            "1 wins\n",
            "board :\n",
            " [[ 1  1  1]\n",
            " [ 0  0 -1]\n",
            " [ 0  0 -1]]\n",
            "\n",
            "playerX epsilon : 0.682554595010387\n",
            "\n",
            "playerO epsilon : 0.682554595010387\n",
            "\n",
            "Game : 39\n",
            "1 wins\n",
            "board :\n",
            " [[ 1 -1  0]\n",
            " [ 1  1  1]\n",
            " [-1 -1  0]]\n",
            "\n",
            "playerX epsilon : 0.6757290490602831\n",
            "\n",
            "playerO epsilon : 0.6757290490602831\n",
            "\n",
            "Game : 40\n",
            "1 wins\n",
            "board :\n",
            " [[-1  0  0]\n",
            " [-1  0  0]\n",
            " [ 1  1  1]]\n",
            "\n",
            "playerX epsilon : 0.6689717585696803\n",
            "\n",
            "playerO epsilon : 0.6689717585696803\n",
            "\n",
            "Game : 41\n",
            "-1 wins\n",
            "board :\n",
            " [[-1 -1 -1]\n",
            " [ 0  1  0]\n",
            " [ 1  1  0]]\n",
            "\n",
            "playerX epsilon : 0.6622820409839835\n",
            "\n",
            "playerO epsilon : 0.6622820409839835\n",
            "\n",
            "Game : 42\n",
            "1 wins\n",
            "board :\n",
            " [[ 1 -1 -1]\n",
            " [ 1  0  0]\n",
            " [ 1 -1  0]]\n",
            "\n",
            "playerX epsilon : 0.6556592205741436\n",
            "\n",
            "playerO epsilon : 0.6556592205741436\n",
            "\n",
            "Game : 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 50.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 wins\n",
            "board :\n",
            " [[ 0 -1  0]\n",
            " [ 1 -1 -1]\n",
            " [ 1  1  1]]\n",
            "\n",
            "playerX epsilon : 0.6491026283684022\n",
            "\n",
            "playerO epsilon : 0.6491026283684022\n",
            "\n",
            "Game : 44\n",
            "1 wins\n",
            "board :\n",
            " [[-1  0  0]\n",
            " [ 0  0 -1]\n",
            " [ 1  1  1]]\n",
            "\n",
            "playerX epsilon : 0.6426116020847181\n",
            "\n",
            "playerO epsilon : 0.6426116020847181\n",
            "\n",
            "Game : 45\n",
            "-1 wins\n",
            "board :\n",
            " [[ 0 -1  1]\n",
            " [ 1 -1  0]\n",
            " [ 1 -1  0]]\n",
            "\n",
            "playerX epsilon : 0.6361854860638709\n",
            "\n",
            "playerO epsilon : 0.6361854860638709\n",
            "\n",
            "Game : 46\n",
            "1 wins\n",
            "board :\n",
            " [[-1  0 -1]\n",
            " [ 1  1  1]\n",
            " [-1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.6298236312032323\n",
            "\n",
            "playerO epsilon : 0.6298236312032323\n",
            "\n",
            "Game : 47\n",
            "1 wins\n",
            "board :\n",
            " [[ 1  1 -1]\n",
            " [-1  1 -1]\n",
            " [ 1 -1  1]]\n",
            "\n",
            "playerX epsilon : 0.6235253948912\n",
            "\n",
            "playerO epsilon : 0.6235253948912\n",
            "\n",
            "Game : 48\n",
            "\n",
            "Draw\n",
            "board :\n",
            " [[ 1 -1  1]\n",
            " [ 1  1 -1]\n",
            " [-1  1 -1]]\n",
            "\n",
            "playerX epsilon : 0.617290140942288\n",
            "\n",
            "playerO epsilon : 0.617290140942288\n",
            "\n",
            "Game : 49\n",
            "-1 wins\n",
            "board :\n",
            " [[-1  1 -1]\n",
            " [ 1  1 -1]\n",
            " [ 1 -1 -1]]\n",
            "\n",
            "playerX epsilon : 0.611117239532865\n",
            "\n",
            "playerO epsilon : 0.611117239532865\n",
            "23 19 50\n",
            "Win percentage: Agent X 46.00%, Agent O 38.00%.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTUzmJs-09_u",
        "outputId": "a3667a7f-7763-4bd4-ef02-4af934e688af"
      },
      "source": [
        "board=Board()\n",
        "print(board.checkWinner())\n",
        "\n",
        "board.state = np.array(((-1,-1,-1), (0,0,0), (0,0,0)))\n",
        "print(board.checkWinner())\n",
        "print(board.getStateHash())\n",
        "pos = board.getAvailablePos()\n",
        "print(\"getAvailablePos\\n\", pos)\n",
        "print(\"checkGameEnded\\n\", board.checkGameEnded())\n",
        "\n",
        "\n",
        "list1 = board.getAvailablePos()\n",
        "print(\"shape\\n\",list1.shape[0])\n",
        "ch1= np.random.choice(list1.shape[0])\n",
        "print(\"random.choice\\n\",ch1)\n",
        "print(\"random action\\n\", list1[ch1])\n",
        "\n",
        "board.state = np.array(((-1,0,0), (0,1,0), (0,0,-1)))\n",
        "print(board.getStateHash())\n",
        "\n",
        "board.state = np.array(((-1,1,1), (1,1,1), (1,-1,-1)))\n",
        "print(board.checkGameEnded())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "-1\n",
            "[[-1 -1 -1]\n",
            " [ 0  0  0]\n",
            " [ 0  0  0]]\n",
            "getAvailablePos\n",
            " [[1 0]\n",
            " [1 1]\n",
            " [1 2]\n",
            " [2 0]\n",
            " [2 1]\n",
            " [2 2]]\n",
            "checkGameEnded\n",
            " False\n",
            "shape\n",
            " 6\n",
            "random.choice\n",
            " 0\n",
            "random action\n",
            " [1 0]\n",
            "[[-1  0  0]\n",
            " [ 0  1  0]\n",
            " [ 0  0 -1]]\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}